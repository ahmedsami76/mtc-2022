{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22240a39-4ef8-438a-a92d-dac99711c1cb",
   "metadata": {},
   "source": [
    "## Connect to Spark standalone cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313abdd1-a083-4dc3-b420-3a5cbfcda122",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/spark/sbin/stop-all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93e9d35-b891-4573-8a52-de3f1ba7b6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "!/usr/local/spark/sbin/start-all.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0c8aec-f18b-4790-9e30-730a3fad496b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pyspark\n",
    "import pymssql\n",
    "import pandas as pd\n",
    "from pyspark import SparkContext, SparkConf, pandas as ps\n",
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e0a75c-bb70-4700-a4fc-2613ba22d2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load PG JDBC driver when starting Spark\n",
    "sparkClassPath =  '/usr/local/spark/jars/postgresql-42.4.1.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a03617-2748-481c-b5e1-c7a1226a646b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    spark.stop()\n",
    "except:\n",
    "    print(\"No Spark Session\")\n",
    "    \n",
    "spark = SparkSession.builder \\\n",
    "        .config(\"spark.driver.extraClassPath\", sparkClassPath) \\\n",
    "        .config(\"spark.jars\", sparkClassPath) \\\n",
    "        .appName(\"Southbridge Analytics\") \\\n",
    "        .master(\"local\") \\\n",
    "        .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1725c2d4-daa9-4ff3-b665-95c7e2ca8554",
   "metadata": {},
   "source": [
    "## Connect to PostgreSQL Server and create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2db6549-3e3d-4c02-a0c6-e39e3282627e",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"jdbc:postgresql:pg\"\n",
    "user = \"postgres\"\n",
    "password = \"P@ssw0rd\"\n",
    "table = \"dvdrental.film\"\n",
    "\n",
    "jdbcDF1 = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://pg:5432/dvdrental\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"dbtable\", \"film\") \\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"P@ssw0rd\").load()\n",
    "\n",
    "jdbcDF2 = spark.read.format(\"jdbc\") \\\n",
    "        .option(\"url\", \"jdbc:postgresql://pg:5432/dvdrental\") \\\n",
    "        .option(\"driver\", \"org.postgresql.Driver\") \\\n",
    "        .option(\"dbtable\", \"address\") \\\n",
    "        .option(\"user\", \"postgres\").option(\"password\", \"P@ssw0rd\").load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ab500b-8a94-4231-8b25-fa0462cb186c",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF1.show(5)\n",
    "jdbcDF2.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a606aeb5-46f4-4763-b214-283248aff9c5",
   "metadata": {},
   "source": [
    "## Write DataFrame to HDFS as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce01e286-5f00-4b4f-a43a-441578e3dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dir in hdfs if not already there\n",
    "os.system('hdfs dfs -mkdir hdfs://localhost:9000/pg-spoke/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b45e65-7bb0-4e7a-ba2a-1bee31301ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "jdbcDF1.write.parquet(\"hdfs://localhost:9000/pg-spoke/pg1.parquet\")\n",
    "jdbcDF2.write.parquet(\"hdfs://localhost:9000/pg-spoke/pg2.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec401bf-0e71-4e41-ac94-94667e2ef0b6",
   "metadata": {},
   "source": [
    "## Validate Parquet from HDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61568e2-7065-4b0f-b0f0-f9b3e51c67a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf1 = spark.read.parquet(\"hdfs://localhost:9000/pg-spoke/pg1.parquet\")\n",
    "testdf2 = spark.read.parquet(\"hdfs://localhost:9000/pg-spoke/pg2.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e973dbb4-2be2-459c-8cb7-ea4118cbfd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdf1.show(2)\n",
    "testdf2.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c9c2c3-7af7-4389-8800-dfb88500e524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
